%  LaTeX support: latex@mdpi.com 
%  In case you need support, please attach all files that are necessary for compiling as well as the log file, and specify the details of your LaTeX setup (which operating system and LaTeX version / tools you are using).

% You need to save the "mdpi.cls" and "mdpi.bst" files into the same folder as this template file.

%=================================================================
\documentclass[brainsci,article,submit,moreauthors,pdftex,10pt,a4paper]{mdpi} 

%
%--------------------
% Class Options:
%--------------------
% journal
%----------
% Choose between the following MDPI journals:
% actuators, admsci, aerospace, agriculture, agronomy, algorithms, animals, antibiotics, antibodies, antioxidants, applsci, arts, atmosphere, atoms, axioms, batteries, behavsci, beverages, bioengineering, biology, biomedicines, biomimetics, biomolecules, biosensors, brainsci, buildings, carbon, cancers, catalysts, cells, challenges, chemosensors, children, chromatography, climate, coatings, computation, computers, condensedmatter, cosmetics, cryptography, crystals, data, dentistry, designs, diagnostics, diseases, diversity, econometrics, economies, education, electronics, energies, entropy, environments, epigenomes, fermentation, fibers, fishes, fluids, foods, forests, futureinternet, galaxies, games, gels, genealogy, genes, geosciences, geriatrics, healthcare, horticulturae, humanities, hydrology, informatics, information, infrastructures, inorganics, insects, instruments, ijerph, ijfs, ijms, ijgi, ijtpp, inventions, jcdd, jcm, jdb, jfb, jfmk, jimaging, jof, jintelligence, jlpea, jmse, jpm, jrfm, jsan, land, languages, laws, life, literature, lubricants, machines, magnetochemistry, marinedrugs, materials, mathematics, mca, mti, medsci, medicines, membranes, metabolites, metals, microarrays, micromachines, microorganisms, minerals, molbank, molecules, mps, nanomaterials, ncrna, neonatalscreening, nutrients, particles, pathogens, pharmaceuticals, pharmaceutics, pharmacy, philosophies, photonics, plants, polymers, processes, proteomes, publications, recycling, religions, remotesensing, resources, risks, robotics, safety, sensors, separations, sexes, sinusitis, socsci, societies, soils, sports, standards, sustainability, symmetry, systems, technologies, toxics, toxins, tropicalmed, universe, urbansci, vaccines, vetsci, viruses, water
%---------
% article
%---------
% The default type of manuscript is article, but can be replaced by: 
% addendum, article, book, bookreview, briefreport, casereport, changes, comment, commentary, communication, conceptpaper, correction, conferenceproceedings, conferencereport, expressionofconcern, meetingreport, creative, datadescriptor, discussion, editorial, essay, erratum, hypothesis, interestingimage, letter, newbookreceived, opinion, obituary, projectreport, reply, retraction, review, preprints, shortnote, supfile, technicalnote
% supfile = supplementary materials
%----------
% submit
%----------
% The class option "submit" will be changed to "accept" by the Editorial Office when the paper is accepted. This will only make changes to the frontpage (e.g. the logo of the journal will get visible), the headings, and the copyright information. Also, line numbering will be removed. Journal info and pagination for accepted papers will also be assigned by the Editorial Office.
%------------------
% moreauthors
%------------------
% If there is only one author the class option oneauthor should be used. Otherwise use the class option moreauthors.
%---------
% pdftex
%---------
% The option pdftex is for use with pdfLaTeX. If eps figure are used, remove the option pdftex and use LaTeX and dvi2pdf.

%=================================================================
\firstpage{1} 
\makeatletter 
\setcounter{page}{\@firstpage} 
\makeatother 
\articlenumber{x}
\doinum{10.3390/------}
\pubvolume{xx}
\pubyear{2017}
\copyrightyear{2017}
\externaleditor{Academic Editor: name}
\history{Received: date; Accepted: date; Published: date}

%------------------------------------------------------------------
% The following line should be uncommented if the LaTeX file is uploaded to arXiv.org
%\pdfoutput=1

%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, calc, indentfirst, fancyhdr, graphicx, lastpage, ifthen, lineno, float, amsmath, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, amsthm, hyphenat, natbib, hyperref, footmisc, geometry, caption, url, mdframed

%=================================================================
%% Please use the following mathematics environments: Theorem, Lemma, Corollary, Proposition, Characterization, Property, Problem, Example, ExamplesandDefinitions, Remark, Definition
%% For proofs, please use the proof environment (the amsthm package is loaded by the MDPI class).

%=================================================================
% Full title of the paper (Capitalized)
\Title{EEG Waveform Analysis with applications to Brain Computer Interfaces}

% Authors, for the paper (add full first names)
\Author{Rodrigo Ramele $^{1,\dagger}$, Ana Julia Villar $^{1}$ and Juan Miguel Santos  $^{1}$*}
% Authors, for metadata in PDF
\AuthorNames{Rodrigo Ramele, Ana Julia Villar and Juan Miguel Santos}

% Affiliations / Addresses (Add [1] after \address if there is only one affiliation.)
\address[1]{%
$^{1}$ \quad Computer Engineering Department, Instituto Tecnológico de Buenos Aires (ITBA); info@itba.edu.ar}

% Contact information of the corresponding author
\corres{Correspondence: rramele@itba.edu.ar; Tel.: +54-9-11-4193-9382}

% Current address and/or shared authorship
\firstnote{Current address: C1437FBH Lavarden 315, Ciudad Autónoma de Buenos Aires, Argentina} 

% Simple summary
%\simplesumm{}

% Abstract (Do not use inserted blank lines, i.e. \\) 
\abstract{The Electroencephalography (EEG) is not just a mere clinical tool anymore.  It has become the de-facto mobile, portable, non-invasive brain imaging sensor to harness brain information in real time and translating or decoding brain signals that can be used to diagnose disease or implement Human Computer Interaction devices.  The automatic processing approach which is based on using quantitative algorithms to detect the cloaked information buried in the signal, outshines the research done by the clinical EEG community which was based intensively on EEG waveforms and the structure of signal plots.  Hence, the purpose of this work is to help to start to fill this gap by doing a review and description of the procedures that have been used to detect patterns in the waveforms, and to perform a benchmarking analysis of them.  }

% We aim to detect specific waveforms mimicking what physicians has been doing since the inception of this fruitful technology.

% Keywords
\keyword{electroencephalography (EEG); ERP,BCI,waveform, signal structure}

% The fields PACS, MSC, and JEL may be left empty or commented out if not applicable
%\PACS{J0101}
%\MSC{}
%\JEL{}
%\AMS{}

% If this is an expanded version of a conference paper, please cite it here: enter the full citation of your conference paper, and add $^\S$ in the end of the title of this article.
%\conference{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Data:

%\dataset{DOI number or link to the deposited data set in cases where the data set is published or set to be published separately. If the data set is submitted and will be published as a supplement to this paper in the journal Data, this field will be filled by the editors of the journal. In this case, please make sure to submit the data set as a supplement when entering your manuscript into our manuscript editorial system.}

%\datasetlicense{license under which the data set is made available (CC0, CC-BY, CC-BY-SA, CC-BY-NC, etc.)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% For Conference Proceedings Papers: add the conference title here
%\conferencetitle{}

%\setcounter{secnumdepth}{4}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Only for the journal Gels: Please place the Experimental Section after the Conclusions

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{section}{-1} %% Remove this when starting to work on the template.

\section{Introduction}

%People with disabilities needs technological solutions for inclusion

%Old people is more likely to be disabled.

%The society is getting old.

%We also have digital gadgets everywhere, so the society needs new ways to interact with those devices.

%So far the interaction with devices has been based on muscular movement, but these trends are pushing the boundary beyond the confines of the body.

Current society is demanding technology to provide the means to realize the utopia of social inclusion for people with disabilities\citep{Wolpaw2002}.  Additionally, as societies are aging \citep{Lutz2008} the incidence of neuromuscular atrophies, strokes and other invalidating diseases is increasing.  Concurrently, the digital revolution and the pervasiveness of digital gadgets have modified the way people interact with the environment through these devices \citep{Domingo2012}.  All this communication is based on muscular movement \citep{Guger2017}, but these trends are pushing this boundary beyond the confines of the body and beyond the limitation of human motion.  A new form of Human Machine communication which directly connects the Central Nervous System (CNS) to a machine or computer device is currently being developed: Brain Machine Interfaces (BMI), Brain Computer Interfaces (BCI) or Brain-Neural Computer Interfaces (BNCI).

At the center of all this hype, we can find a hundredth year old technology, rock-solid as a diagnosis tool, which greatly benefited from the shrinkage of sensors, the increase in computer power and the widespread development of wireless protocols and advanced electronics: the Electroencephalogram (EEG) \citep{Schomer2010}.

EEG sensors are wearable \citep{Puce2017} non-invasive, portable and mobile \citep{DeVos2014}, with excellent temporal resolution, and acceptable spatial resolution \citep{Hartman2005}.  This humble diagnosis device is been transformed into currently the best approach to detect, out-of-the lab in an ambulatory context, information from the Central Nervous System and to use that information to volitionally drive cars, steer drones, write emails, or control wheelchairs \citep{Yuste2017}.

The clinical and historical tactic to analyze EEG signals were based on detecting visual patterns out of the EEG trace or polygraph\citep{Hartman2005}: multichannel signals were extracted and continuously plotted over a piece of paper. Electroencephalographers or Electroencephalography technician have decoded and detected patterns along the signals by visually inspecting them \citep{Schomer2010}.   Nowadays clinical EEG still remains a visually interpreted test \citep{Hartman2005}.

In contrast, automatic processing, or quantitative EEG (qEEG), was based first on analog electronic devices and later on computerized digital processing methods \citep{Jansen1991}.  They implemented mathematically and algorithmically complex procedures to decode the information associated with a clinical condition, or even some higher cognitive state \citep{Yuste2017}.  The best materialization of the automatic processing of EEG signals rests in the BCI discipline, where around $71.2\%$ is based on noninvasive EEG \citep{Guger2017}.  

%rich clinical literature

Hence, the traditional and knowledgeable approach was mainly overshadow particularly in BCI Research, and the waveform of the EEG was replaced by pragmatically sound procedures that were difficult to link to existing clinical EEG knowledge.  We aim to help fix this gap by providing a review of the methods which emphasize the waveform, the shape of the EEG signal and that can help to decode them in a supervised and semi-automated way.

The aim of this study is twofold: first to review current literature of EEG processing techniques which are based on analysis of the waveform.  The second is to evaluate and study these methods by analyzing its classification performance against a pseudo-real dataset. We believe that the importance of waveform analysis methods, as described here, is that by using this methodology, collaboration could be fostered because there is a clear description and characterization of the signal, where the extensive literature which explores clinical EEG can be reviewed from the same shared perspective \citep{Nijboer2009,Wei2017}. 

This article unfolds as follows: Section \ref{EEG} will provide a brief introduction to EEG and the particularities of the EEG waveform characterization.  Section \ref{Algorithms} will explain the algorithms based on the waveform that will be analyzed.  In Section \ref{Experimental} the experimentation procedure will be explained.  Results will be presented in Section \ref{section:results} and finally Discussion and Conclusions will be established in the final sections.

\section{Electroencephalography}
\label{EEG}

The Electroencephalography consists on the measurement of small variations of electrical currents over the scalp.  It is one of the most widespread used methods to capture brain signals and was initially developed by Hans Berger in 1924 and has been extensively used for decades to diagnose neural diseases and other medical conditions.

The first characterization that Dr. Berger detected was the Visual Cortical Alpha Wave, the \textit{Berger Rythm} \citep{Jansen1991}.  He understood that the amplitude and shape of this rhythm was coherently associated to a cognitive action (eyes closing).  
We should ask ourselves if the research advancement that came after that discovery would have happened if it weren't so evident that the shape alteration was due to a very simple and verifiable cognitive process.

The EEG signal is a highly complex multi-channel time-series.  It can be modeled as a linear stochastic process with great similarities to noise \citep{Thakor2004}.  It is measured in microvolts, and those slightly variations are contaminated with heavy endogenous artifacts and exogenous spurious signals.  
 
\begin{figure}[H]
\centering
\includegraphics[height=6cm,width=12cm]{images/sampleeeg.eps}
\caption{Sample EEG signal obtained from g.Tec g.Nautilus.  Time axis is in seconds and five seconds are displayed.  The eight channels provided by this device are shown.}
\label{fig:sampleeeg}
\end{figure}

%locations.eps

The device that captures these small variations in current potentials over the scalp is called the Electroencephalograph.  Electrodes are located in predetermined positions over the head, usually embedded in saline solutions to facilitate the electrophysiological interface and are connected to a differential amplifier with a high gain which allowed the measurement of tiny signals. Although initially analog devices were developed and used, nowadays digital versions connected directly to a computer are pervasive.  A detailed explanation on the particularities and modeling of EEG can be obtained from \citep{Jackson2014}, and a description of its electrophysiological aspects from \citep{Haberman2012}.

Overall, EEG signals can be described by their phase, amplitude,  frequency and \textit{waveform}.  The following components regularly  characterize EEG signals:

\begin{itemize}
\item Artifacts:  These are signal sources which are not generated from the CNS, but can be detected from the EEG signal.  They are called endogeneous or physiological when they are generated from a biological source like muscles, ocular movements, etc., and exogeneous or non-physiological when they have an external electromagnetic source like line induced currents or electromagnetic noise\citep{Weeda2012}.
\item Non-Stationarity: the statistical parameters that describe the EEG as a random process are not conserved through time, i.e. its mean and variance, and any other higher-order moments are not time-invariant \citep{Jansen1991}.
\item DC drift and trending: in EEG jargon, which is derived from concepts of electrical amplifiers theory, Direct Current (DC) refers to very low frequency components of the EEG signal which varies around a common center, usually the zero value.  DC drift means that this center value drifts in time.  Although sometimes considered as a nuisance that needs to get rid of, it is known that very important cognitive phenomena like Slow Cortical Potentials or Slow Activity Transients in infants do affect the drift and can be used to understand some particular brain functioning \cite{Schomer2010}.
\item Basal EEG activity: the EEG is the compound summation of myriads of electrical sources from the CNS.  These sources generate a baseline EEG which shows continuous activity with a small or null relation with any concurrent cognitive activity or task.
\item Inter-subject and intra-subject variability: EEG can be affected by the person's behavior like sleep hygiene, caffeine intake, smoking habit or alcohol intake previously to the signal measuring procedure \citep{Farzan2017}.
\end{itemize}

Regarding how the EEG activity can be related to an external stimulus that is affecting the subject, it can be considered as

\begin{itemize}
\item Spontaneous: generally treated as noise or basal EEG.
\item Evoked: activity that can be detected synchronously after some specific amount of time after the onset of the stimulus.  This is usually referred as time-locked.  In contrast to the previous one, it is often called Induced activity.
\end{itemize}

\noindent Additionally, according to the existence of a repeated rhythm, the EEG activity can be understood as

\begin{itemize}
\item Rhythmic: EEG activity consisting in waves of approximately constant frequency.  It is often abbreviated RA (regular rythmic activity). They are loosely classified by their frequencies, and their naming convention was derived from the original naming used by Hans Berger himself, and after Alpha Waves (10 Hz), it came Delta (4 Hz), Theta (4-7 Hz), Sigma (12-16 Hz), Beta (12-30 Hz) and Gamma (30-100 Hz).  
\item Arrhythmic: EEG activity in which no stable rhythms are present.  
\item Dysrhythmic: Rhythms and/or patterns of EEG activity that characteristically appear in patient groups and rarely seen in healthy subjects.
\end{itemize}

The number of electrodes and their positions over the scalp determines a \textbf{Spatial Structure}: signal elements can be generalized, focal or lateralized, depending on in which channel (i.e. electrode) they are found.

%Finally, indexes can be derived as  CFC, Cross Frequency Coupling,  Phase-Amplitude Coupling, Phase-Phase Coupling.


\subsection{EEG Waveform Characterization}

The shape of the signal, the waveform, can be defined as the graphed line that represents the signal's amplitude plotted against time. It can also be called EEG biomarker,  EEG pattern, signal shape, signal form and a morphological signal \citep{Jansen1991}.

The signal context is crucial for waveform characterization, both in a spatial and in a temporal domain \citep{Jansen1991}.  Depending on the context, some specific waveform can be considered as noise while in other cases is precisely the element which has a cognitive functional implication.

%aforegoing
%hitherto

%phenomenological, the signal is treated as a black box.

%Signal Morphology is not precisely defined in the literature but may refer to
%
%\begin{itemize}
%\item RA (regular rythmic activity) 
%\item low-voltage rapid activity 
%\item sharp waves
%\item longitudinal-bipolar and transverse- bipolar montages (Clinical EEG)
%\end{itemize}

A waveform can have a characteristic shape, a rising or falling phase, a pronounced plateau or it may be composed of ripples and wiggles. In order to describe them, they are characterized by its amplitude, the arch, whether they have (non)sinusoidal shape, by the presence of an oscillation or imitating a sawtooth (e.g. Motor Cortical Beta Oscillations).  The characterization by their sharpness is also common, particularly in Epilepsy, and they can also be identified by their resemblance to spikes (e.g. Spike-wave discharge).

Other depictions may include, subjective definitions of sharper, arch comb or wicket shape, rectangular, containing a decay phase or voltage rise, peaks and troughs, short term voltage change around each extrema in the raw trace.  Derived ratios and indexes can be used as well like peak and trough sharpness ratio, symmetry between rise and decay phase and slope ratio (steepness of the rise period to that of the adjacent decay period).  For instance,  wording like "Central trough is sharper and more negative that the adjacent troughs" are common in the literature.

Other regular characterizations which are based on shape features may include:

\begin{itemize}
\item Attenuation: Also called suppression or depression. Reduction of amplitude of EEG activity resulting from decreased voltage. When activity is attenuated by stimulation, it is said to have been "blocked" or to show "blocking".
\item Hypersynchrony: Seen as an increase in voltage and regularity of rhythmic activity, or within the alpha, beta, or theta range. The term suggest an increase in the number of neural elements contributing to the rhythm.
\item Paroxysmal: Activity that emerges from background with a rapid onset, reaching (usually) quite high voltage and ending with an abrupt return to lower voltage activity. Though the term does not directly imply abnormality, much abnormal activity is paroxysmal.
\end{itemize}

\begin{itemize}
\item Monomorphic: Distinct EEG activity appearing to be composed of one dominant activity
\item Polymorphic: distinct EEG activity composed of multiple frequencies that combine to form a complex waveform.
\item Transient. An isolated wave or pattern that is distinctly different from background activity.
\end{itemize}


%\subsection{EEG Patterns}
%
%%The clinical EEG patterns are identified by the shape of waveform amplitude plotted against time.
%
%Non-exhaustive list of transient events
%Waveform characterization is of quite importance in terms of Event Related Potentials.  
%Determination of transient events, and particularly amplitude of different subcomponents, latency or even phase, has proved very importan concequences in terms of the different cognitive approach.
%
%%inverse problem is mathematically intractable Voytek 2009
%
%Oscillatory activity can also have their differente or distinctive waveforms.  Slow oscillations, which are assosiated with REM, sawtooth-shaped.
%Sleep spindles can also be considered oscilations and they have a distintinc form assosiated with stage 2 dream.
%Visual Cortical alpha and rolandic central mu waves arch-like structure (similar to the greek letter mu).  Slope Ratio.  Trough voltage remains contstant while peak voltage fluctuates.   Steep slopes,   Amplitude asymmetry 
%ponto-geniculo-occipital
%(PGO) waves.
%Rhythms in neural activity are observed across various temporal and spatial scales and are often
%referred to as oscillations (see Glossary) [1]. Traditionally, neural oscillations have been
%clustered into canonical frequency bands, including delta (1–4 Hz), theta (4–8 Hz), alpha (8–
%12 Hz), beta (15–30 Hz), gamma (30–90 Hz), and high gamma (>50 Hz). These bands roughly
%correspond to frequency ranges commonly observed in human electroencephalography (EEG)
%studies. Although they have been observed for nearly a century, recent theories suggest that
%these oscillations play an active role in neural communication.  Hippocampal theta oscillations, for example, are among the best-studied rhythms in the local field potential (LFP); they have a stereotyped sawtooth shape. In sleep research sleep 2 stage the background of KComplex and sleep spindles is theta waves
%
%%by application to Brain Computer Interfaces or EEG diagnosis (BCI a review, BCI Vidal 1973)
%
%
%
%%(e.g. FIRDA - Frontal Intermittent Rhythmic Delta) and posteriorly in children e.g. OIRDA - Occipital Intermittent Rhythmic Delta).
%
%%alpha dissapears when alerting by any mechanism (thinking, calculating)
%
%a) Spike: a transient with a pointed peak and a duration from 20 to under 70 msec.
%b) Sharp wave: a transient with a pointed peak and duration of 70-200 msec.
%
%Some initial works on EEG explored the idea to extend human capacities analyzing EEG waveforms  (automatic detection of k complexes), (A Waveform Analyzer Applied to the Human EEG) where a feature from amplitude and frequency of its signal and its derivative in time-domain is used.  Althought CASENET REFERENCe explored "waveform" structure they were purely based on spike detection based on feeding artificial neural networks.  
%
%ACA VA EL RESTO DE LOS METODOS (fujimori, PAA, etc).  Uchida 1999

The traditional clinical approach consists in analyzing the paper strip that is generated by the plot of the signal obtained from the device.  Expert technician and physicians analyze visually the plots looking for specific patterns that may give a hint of the underlying cognitive process or pathology.   Atlases and guidelines were created in order to help in the recognition of these complex patterns.   Even Video-electroencephalography scalp recordings are routinely used as a diagnostic tools \citep{Giagante2003} .  The clinical EEG research has also focused on temporal waveforms, and a whole branch of electrophenomenology has arisen around EEG \textit{graphoelements} \citep{Schomer2010}.  

Sleep Research has been studied in this way by performing Polysomnographic recordings (PSG)  \citep{Rodenbeck2006}, where the different sleep stages are evaluated by visually marking waveforms or graphoelements in long-running electroencephalographic recordings, looking for patterns based on standardized guidelines.   Visual characterization includes the identification or classification of certain waveform components, or transient events, based on a subjective characterization (e.g. positive or negative peak polarity) or the location within the strip.  It is regular to establish an amplitude difference between different waveforms from which a relation between them is established and a structured index are created (e.g. sleep K-Complex is well characterized based on rates between positive vs negative amplitude) \citep{Uchida1999}.  Other relevant EEG patterns for sleep stage scoring are alpha, theta, and delta waves,  sleep spindles, polysplindles, vertex sharp waves (VSW), and sawtooth waves (REM Sleep).

Moreover, EEG data acquisition is a key procedure during the assessment of patients with focal Epilepsy for potential seizure surgery, where the source of the seizure activity must be reliably identified. The onset of the Epileptic Seizure is defined as the first electrical change seen in the EEG rhythm which can be visually identified from the context and it is verified against any clinical sign indicating seizure onset.  The interictal epileptiform discharges (IEDs) are visually identified from the paper strip, and they are also named according to their shape: spike, spike and wave or sharp-wave discharges\citep{EEGIntro}.  

%Seizures captured in their entirety typically show progression from low-voltage, high-frequency spikes to high-voltage, low-fre- quency spike-and-slow wave activity, before stopping abruptly and being replaced by background slowing or suppression (Fig. 29.9). Usual morphologic features include typical rhythmic, gen- eralized, symmetric spike-and-waves or polyspikes and waves at 2 to 3.5 Hz; atypical spike and wave with lower frequency and less symmetry; multiple spike-and-wave (repetitive complexes of two or more spikes followed by a slow wave); and high-voltage, repetitive, rhythmic, focal or generalized delta activity with inter- mixed spikes, sharp waves, or sharp components (Fig. 29.24) (45). Diagnosis is more difficult when the seizure (or SE) pre- cedes the beginning of the tracing and continues beyond its end. In such cases, rhythmic sharp features, typically faster than 1 Hz, may be seen, often with variability.

%Finally, there are specific EEG patterns that can be used to determine Depth of anestisia. 

%The waveform of the EEG depends on the settings of the capturing device.  The most important part to consider is that of montage.  It could be bipolar or referencial.  The traditional convention, somehow maintained in neuro research, downward polarity was considered negative and upward deflection for negative (Knott, 1985)  It is of utmost importance to remark that  EEG waveforms represent the differential voltage between a given electrode and the recording reference. It is therefore clear that the choice of reference completely determines EEG waveforms (Lehmann, 1987; Dien, 1998), an important methodological consideration that all too often is still not recognized in the EEG literature. For example, recording with a vertex (Cz) reference would lead to small EEG deflections in the proximity of Cz due to potential synchronization of firing activities within closely spaced brain regions and volume propagation of the EEG signal. Similarly, recording with mastoid or linked ears montage would lead to rather small waveforms at electrodes positioned over temporal brain regions (Pivik et al., 1993). Digital EEG can be rereferenced offline.  

%
%BCI --> distinguishing the pertinent signal characteristics from extraneous content and representing them in a compact or menaingful form, amenable to interpretation by a human or computer (Wolpaw and Wolpaw)

%Transient phenomena allows also to record occurrence and temporal sequence (mimicking spike analysis in neuro reserach)

%The traditional approach do not consider waveform even though the brain oscilations are in general nonsinusoidal (reference)
% Waveform characterization, on the other hand, has been extensively used in artifact detection and averaging.


\begin{table}[H]
\caption{Subjective EEG characterization methods found in the surveyed literature.}
\centering
%% \tablesize{} %% You can specify the fontsize here, e.g.  \tablesize{\footnotesize}. If commented out \small will be used.
\begin{tabular}{ccc}
\toprule
\textbf{Method}	& \textbf{Phenomena} & \textbf{Reference}	\\
\midrule
SVM     & m-c  & $50\%$ \\
NN       & m-c  & $45\%$ \\
HGO  & PO8 & $25\%$ \\
MP 1 & PO8 & $25\%$ \\
PE     & Cz & $20\%$ \\
RS     & Fz & $15\%$ \\
RS     & m-c  & $15\%$ \\
MP 2 & PO7 & $10\%$ \\
SHCC & P4 & $10\%$ \\
NN s-c & Fz & $10\%$ \\
\bottomrule
\end{tabular}
\label{tab:results}
\end{table}


\section{Materials and Methods}

The search of methods based on waveforms is conducted by following the PRISMA~\citep{Moher2009} guidelines.  Search is performed on Google Scholar, Semantic Web and IEEE Xplore search engines by the terms "Waveforms" OR "Shape" OR "Morphology" OR "Visual inspection" + "EEG".

The following criteria is proposed to identify methods which are based on the signal's waveform:

\begin{enumerate}
\item The analysis take account the shape of the plot of the signal.
\item The pattern can be identified and verified by visual inspection.
\item The pattern matching is performed in time-domain.
\item The method encompass a feature extraction procedure.
\item The feature extraction procedure allows to create a template dictionary.
\item A single-channel processing scheme.
\end{enumerate}

As described in \citep{allen2004signal} the Pattern Matching problem in Signal processing is finding a signal given the region that best describes the structure of the prototype signal.   All these algorithm were implemented on MATLAB 2014a (Mathworks Inc., Natick, MA, USA). 

\subsection{EEG Waveform Analysis Algorithms}
\label{Algorithms}

Shape or waveform analysis methods are considered as nonparametric (in opposition to statistical or dynamical models).  They explore signal's time-domain metrics or even derive more complex indexes from it \citep{Thakor2009}. 

One of the earliest approach to automatically process EEG data is the Peak Picking method.  Although of limited usability, peak picking has been used to determine latency of transient events in EEG \citep{Jaskowski2000,Zhang2011}.  Straightforward in its implementation, it consists in selecting a component, a simple component based on the expected location of its more prominent deflection \citep{Ouyang2017}.  Evoked Potentials (EPs) and Event Related Potentials (ERPs) are transient component that may arise as a brain response to an external visual, tactile or auditory stimulus.  Particularly, EPs are regularly used to assess auditory response in infants. They are precisely characterized in this manner, where the name of many of the EEG features evoke directly a peak within the component, e.g. P300 or P3a P3b or N100.  This leads to a natural procedure to classify them visually by selecting appropriate peaks and matching their positions and amplitudes in an orderly manner.  The letter provides the polarity (Positive or Negative) and the numbering shows the time referencing the stimulus onset, or the ordinal position of each peak (first, second, etc).   

A related method is used in \citep{Alvarado-Gonzalez2016} where the area under the curve of the EEG is sumarized to derive a feature.  This was even used in the seminal work of Farwell and Donchin on P300 \citep{Farwell1988,WolpawJonathanR2012}. Additionally, a logarithmic graph of the peak-to-peak amplitude which is called amplitude integrated EEG (aEEG) \citep{Shah2015} is used nowadays in Neonatal Intensive Care Units.

Other works on EEG explored the idea to extend human capacities analyzing EEG waveforms \citep{Klein1976} where a feature from the amplitude and frequency of its signal and its derivative in time-domain is used.  Moreover, other works explored the use of Mathematical Morphology \citep{Yamaguchi2009}, where the time-domain structure of contractions and dilations were studied. Finally the proposals of Fujimori, Uchida and the PAA \citep{Uchida1996} algorithm are few of the earliest proposals where the idea of capturing the shape of the signal were established.

%Althought CASENET REFERENCe explored "waveform" structure they were purely based on spike detection based on feeding artificial neural networks.  

 %(fujimori, PAA, etc).  Uchida 1999

%\subsubsection{Averaging Methods}
%
%The methods that allow to identified waveforms are used to determine different alignments while averaging epochs.
%
%This long-standing problem has been tackled from different perspectives.  Woody's Template Matching is perhaps the best effort as well as Pham, and Tuan and others EML.
%
%Dictionary, template based method.  Many do not consider the waveform, albeit they do use a set of templates obtained from a dictionary.
%
%Cross Covariance with Template or Cross Correlation or ACF: Autocorrelation Function: PHAM METHOD
%
%Applying a FIR filter with templates 
%
%Krusienski et al 2007
%Serby et al 2005
%
%extended to wavelent analysis.
%
%Dynamic Time Warping and other Warp Averaging methods were also used.
%
%Wrapping Analysis
%
%Warp averaging

According to the defined criteria, the algorithms that will be evaluated are as follows:

\begin{itemize}
\item Matching Pursuit
\item Permutation Entropy
\item Slope Horizontal Chain Code
\item Histogram of Gradient Orientations
%\item Merging of Increasing and Decreasing Sequences
%\item Local Binary Patterns (1-D LNBP, 1D-LBP and LBP)
\end{itemize}

All these methods provide a feature that can be used as a template, whereas all of them are based on metrics that can be extracted from the shape of the signal.  These features can be used to create dictionaries or template databases.  These templates provide the basis for the pattern matching algorithm and offline classification.

\subsection{Matching Pursuit - MP 1 and MP 2}

\textit{Pursuit} algorithms refer, in their many variants, as blind source separation \citep{Comon2010} techniques that assume that the EEG signal is a linear combination of different sparse sources extracted from a template's dictionaries.  \textit{MP}, the most representative of this algorithms, is a greedy variant that decomposes a signal into a linear combination of waveforms, called atoms, that are well localized in time and frequency \citep{ChandranKS2016}.  Given a signal, this optimization technique, tries to find the indexes of atoms and their weights (contributions) that minimize,


\begin{equation}
\varepsilon =  \left\lVert   x(n,c) - \sum_{i=1}^{m} w_i g_{yi}   \right\rVert
\label{eq:mperror}
\end{equation}

which is the error from the signal approximation constructed by the weighted atoms.  The algorithm goes by first setting the approximation signal by the original signal itself,  

\begin{equation}
\tilde{x_{0}}(n,c) = x(n,c), k \leftarrow 1
\label{eq:multiclassificationrow}
\end{equation}

Hence, it finds the best template, out of the dictionary, that matches current approximation (original signal).  

\begin{equation}
g_{yk}(n) = \arg \max_{g_{yi}} \left\lVert < \tilde{x_{k}}(n,c), g_{yi} > \right\rVert 
\label{eq:multiclassificationrow}
\end{equation}

where $g_{yi}$ are all the available scaled, translated and modulated atoms from the dictionary.  This determines the atom selection process, and their contribution is calculating based on 

\begin{equation}
w_{k} =  \frac{< \tilde{x_{k}}(n,c), g_{yk} >}{g_{yk}}
\label{eq:multiclassificationrow}
\end{equation}

with $k$ representing the index of the selected atom $g_{yk}$.  Finally the contribution of each atom is subtracted from the next approximation, refining the approximation process \citep{Cohen2008,Sanei1997, Mallat1993}

\begin{equation}
\tilde{x_{k+1}}(n,c)=  \tilde{x_k}(n,c) - w_{k} g_{yk} (n), k \leftarrow k + 1
\label{eq:multiclassificationrow}
\end{equation}

Two variants of this algorithm are evaluated. In \textit{MP 1} the dictionary is directly constructed with the normalized templates from Fig \ref{fig:dictionaryfig}.  In \textit{MP 2} the coefficients of  Daubechies least-asymetric wavelet with 2 vanishing moments atoms are used to construct the dictionary.  The first version, the matching against the template is evaluated according to Equation \ref{eq:mperror} directly, whereas for the latter to craft each feature is crafted by decomposing the signal in its coefficients and building a vector with them.

\begin{equation}
f =  {\bigg ( w_{i} \bigg )}_{1}^{m} 
\label{eq:multiclassificationrow}
\end{equation}


%On the other hand, Morphological Component Analysis is a variant form of Blind Source Separation which can be considered the extension of Matching Pursuit algorithm. (cita a esa parte del paper).


\subsection{Permutation Entropy - PE}

Bond and Pompe Permutation Entropy has been extensively used in EEG processing, particularly for Epilepsy pre-ictal detection \citep{Bandt2002}.  This method generates a code based on the orderly arrangement of sequential samples, and then derives a metric which is based on the amount of entropy of each code within the signal.   For instance, a pure random signal, will achieve the maximum entropy value due to the probability of each code being equal for all of them. This method is the best representative of Waveform Complexity: Lempel-Ziv method L-Z complexity are other variants which use a different definition (Permutation Entropy a new feature for brain computer interfaces).

A signal represented by 

\begin{equation}
(x_1,x_2,...,x_{N})
\label{eq:pesignal}
\end{equation}

is resampled by $\tau$ values doing

\begin{equation}
(x_n,x_{n+\tau},x_{n+2 \tau}...,x_{n+(N-1)\tau})
\label{eq:pesignal}
\end{equation}

\subsection{Slope Horizontal Chain Code - SHCC}

This method is an extension of Slope Chain Code (SCC) (ref a SCC paper y a SHCC paper), and a code of a sequence of sample points is generated based on the angle between the horizontal segment and any segment, one by one.  This method can be encompass as a syntactic analysis technique, where the EEG segment is represented as a series of elementary patterns, similar to tokens, due to the quantization of angles.

A signal, can be represented by a list of ordered-pairs $e$,

\begin{equation}
e = \left[ (x,y)_{1}, (x,y)_{2}, ..., (x,y)_{N} \right]
\label{eq:shccdelta}
\end{equation}

\noindent and it can be divided into $G$ different blocks.  These blocks are obtained by resampling the original signal from the index 

\begin{equation}
g = \lfloor n + ( m \Delta ) + 0.5 \rfloor
\label{eq:shccdelta}
\end{equation}

\noindent with $n$ being the original sampling index, and $ 1 \leq t \leq N $.  On the other hand, $\Delta$ can be obtained by

\begin{equation}
\Delta = \bigg \lceil \frac{N}{G+1} \bigg \rceil
\label{eq:shccdelta}
\end{equation}

\noindent with $ G < N $. The value $m$ can be derived from

\begin{equation}
m = sign \bigg (  \frac{N-1}{\Delta} \bigg )  \bigg \lfloor \left\lvert \frac{T-1}{\Delta} \right\lvert \bigg \rfloor
\label{eq:shccdelta}
\end{equation}

This resampling produces a new sequence of values,

\begin{equation}
e = \left[ (x',y')_{1}, (x',y')_{s}, ..., (x',y')_{G} \right]
\label{eq:shccdelta}
\end{equation}

Next step is the normalization of each paired-values according to

\begin{equation}
\textbf{x} = \frac{1}{\max(x') - min(x')} ( \textbf{x'} - \min(x') \textbf{1} )
\label{eq:shccdelta}
\end{equation}

\begin{equation}
\textbf{y} = \frac{1}{\max(y') - min(y')} ( \textbf{y'} - \min(y') \textbf{1} )
\label{eq:shccdelta}
\end{equation}

\noindent effectively yielding $x,y \in [0,1]$.

Finally, the feature is constructed by calculating the point-to-point slope against the horizontal plane,

\begin{equation}
f = \bigg (  \frac{y_{s}-y_{s-1}}{x_{s}-x_{s-1}}  \bigg )_{2}^{G} 
\label{eq:shccdelta}
\end{equation}


\subsection{Histogram of Gradients Orientations - HGO}

This Histogram of Gradient Orientations is based on using Computer Vision techniques to extract directly information from a signal based on the plot of a signal on a 2D image.  This mimicks exactly what a person is doing by visually inspecting the plot, and the waveform.  To do that, the region of the image where the signal is located is divided in a $4 x 4$ block and the signal bidimensional gradients is calculated.  For each block within the patch, a histogram of gradient orientations, 8 circular orientations, is calculated.  This histogram is concatenated for all the 16 blocks and a feature is thus formed.  The details of the method can be found here \citep{Ramele2016}.  This method was implemented using the VLFeat  \citep{Vedaldi2010} Computer Vision libraries.

\begin{equation}
f = {\bigg ( h(i,j,\theta) \bigg )}_{i,j,\theta}
\label{eq:multiclassificationrow}
\end{equation}

%\subsection{Merger of Increasing and Decreasing Sequences}

%Stepwise downsampling 

\subsection{Experimental Protocol}
\label{Experimental}

Farwell and Donchin P300 Speller \citep{Farwell1988} is one the most used BCI paradigms to implement a thought translation device and to send commands to a computer in the form of selected letters, similar to typing in a virtual keyboard.  This procedure exploits a cognitive phenomena called oddball paradigm: along the EEG trace of a person which is focusing on a sequence of two different visual flashing stimulus, a particular and distinctive transient component is found each time the expected stimulus flashes.  This is cleverly utilized in the P300 Speller, where rows and columns of a 6x6 matrix flashes randomly but only the flashing of a column or row where the letter that a user is focusing will trigger concurrently the P300 ERP along the EEG trace.

%Algorithms based on qEEG can detect this component in a good-enough single-trial approach [P300 Summary], but at the same time, these algorithms do not establish a clear relationship with the P300 ERP. Hence it is difficult to establish a backward mapping back to a certain visual pattern within the waveform.

In order to verify each algorithm in a controlled procedure, a real ERP template is superimposed into a real EEG stream.  This trace was experimentally obtained by a subject which was observing the flashing of the stimulus matrix during a P300 Speller procedure but did not engage in focusing on anyone in particular. Everything is there, except the P300 ERP component. By implementing this pseudo-real approach, it is possible to effectively control null-signals and to adjust the shape of this evoked potential in accordance to a similar procedure used in similar works \citep{Ouyang2017,Jaskowski2000,QuianQuiroga2003}.

The experiments are as follows:

\begin{itemize}
\item Pseudo-real dataset Classification Performance: the letter classification performance of each one of these methods.
\item Latency Noise: Gaussian noise is added to the latency where the ERP template is injected into the EEG stream.
\item Component Amplitude Noise: the different components of the ERP template are altered to make them less distinguishable.
\end{itemize}

Finally results for the same methods while offline processing a public dataset of real P300 patterns are also shown.

\subsubsection{Pseudo-Real Dataset Generation}

The template ERP is extracted from the Subject $8$ of the public dataset 008-2014  \citep{Riccio2013} published on the BNCI-Horizon website \citep{Brunner2014} by IRCCS Fondazione Santa Lucia. Segments from the EEG signal are labeled as hit and are extracted for the trial number $2$, and they are point-to-point coherently averaged.  This P300 ERP can be seen in Fig.  \ref{fig:erptemplate1}. 

An EEG stream with null-P300 signal everywhere is obtained by the following procedure: 
The participant is recruited voluntarily and the experiment is conducted anonymously in accordance with the Declaration of Helsinki published by the World Health Organization.  No monetary compensation is handed out and he/she agree and sign a written informed consent.  This study is approved by the \textit{Departamento de Investigación y Doctorado, Instituto Tecnológico de Buenos Aires (ITBA)}.  The participant is healthy and have normal or corrected-to-normal vision and no history of neurological disorders. This voluntary is of unspecified gender, aged between 20-30 years old.  EEG data is collected in a single recording session. She/He is seated in a comfortable chair, with her/his vision aligned to a computer screen located one meter in front of him.  The handling and processing of the data and stimuli is conducted by the OpenVibe platform~\citep{Renard2010}.  Gel-based active electrodes (g.LADYbird, g.Tec, Austria) are used on locations Fz, Cz, Pz, Oz, P3,P4, PO7 and PO8 according to the 10-20 international system.  Reference is set to the right ear lobe and ground is preset as the AFz position.   Sampling frequency is set to 250 Hz, which is the closest possible to the one used with the other dataset. 

The participant is instructed to passively watch the flashing screen while not focusing on any particular letter.  A questionnaire is handed out at the end of the experiment with questions about how the participant felt during it, without giving more details.  

%This P300 Speller protocol consist in the flashing of 35 trails of 35 letters (7 words of 5 letter) where the intensification sequence of 6 rows and 6 columns is repeated 10 times for each letter.  More details can be found on the published work of \citep{Riccio2013}.

Fig. \ref{fig:gaincheck} shows the result of superimposing the template signal into EEG stream, time-locked to the stimulus onset.   These 12 point-to-point averaged segments correspond to the first trial of the EEG stream.

%The original signal-to-noise ratio was calculated as Hue 2010.

\begin{figure}[H]
\centering
\includegraphics[width=12cm]{images/erptemplate1.eps}
\caption{ERP Template obtained from the coherent point-to-point ensemble average of subject Eight obtained from the BNCI Horizon public dataset. The template is $1s$ long which is 256 sample points, and the eight channels are superimposed with different colors.  The P1, N1 and P300 peaks can be seen.}
\label{fig:erptemplate1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=10cm]{images/doublegain.eps}
\includegraphics[width=10cm]{images/triplegain.eps}
\caption{Eight-channel EEG signal superimposed with the ERP Template.  (Left) EEG trace of the original signal. (Right) The same signal segment with the added template.}
\label{fig:doubleandtriplegain}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=15cm]{images/GainCheck.eps}
\caption{These are the point-to-point averaged signals for the first trial.  The ERP was injected on class 3 and 9.}
\label{fig:gaincheck}
\end{figure}

\subsubsection{Classification} \label{section:classification}

To analyze how each method identifies the hidden P300 signal, the same classification algorithm is used.   The original dataset is composed of 35 trials to decode 7 words of 5 letters  of the P300 matrix.  Each trial is composed of 10 intensification sequences of the 6 columns and 6 rows \citep{Riccio2013}.  The averaging procedure aims to extract the superimposed ERP Template and cancel out everything else on each segment.  

This classification procedure identifies the row and column, matching to the template $T$ by computing  

\begin{equation}
\hat{row} = \arg \min_{u \in \{1,\dots,6\}} \sum_{q \in NN_T(f^{row}_u)}^{} \left\lVert q -  f^{row}_u \right\rVert ^2
\label{eq:multiclassificationrow}
\end{equation}

\noindent and

\begin{equation}
\hat{col} = \arg \min_{u \in \{7,\dots,12\}} \sum_{q \in NN_T(f^{col}_u)}^{} \left\lVert q -  f^{col}_u \right\rVert ^2
\label{eq:multiclassificationcol}
\end{equation}

\noindent where $NN_T(f^l_u),\;l\in\{row,{col}\}$  is the set of the $k$ nearest neighbors to $f^l_u$ and $q$ is a template feature that belongs to it.  This set is obtained by sorting all the elements in the dictionary $T$ based on the distances between them and $f^l_u$, choosing the $k$ smaller elements. This procedure is a modification of the k-NBNN  algorithm~\citep{Boiman2008}.

By computing the aforementioned equations, the letter of the matrix can be determined from the intersection of the row $ \hat{row} $ and column $ \hat{col} $.  %Figure~\ref{fig:classification} shows a scheme of this process. 

%\subsubsection{Parameters}

%The parameters for each method were derived from bibliography were they are introduced 


%Each method has its own set of parameters. To define them an optimization problem was defined and the set of values for each method that achieve the maximum performance value for 

\begin{figure}[H]
\centering
\includegraphics[width=15cm]{images/dictionary.eps}
\caption{Coherently averaged signals containing the superimposed ERP.  Each one is extracted from the 15 first trials (2 signals from each trial, one belonging to the column and the other to the row).  These are the templates used to build the dictionary $T$ and that are used by the classification algorithm described in \ref{section:classification}.}
\label{fig:dictionaryfig}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
\label{section:results}

Results are shown in Table \ref{tab:results} and in Figure \ref{fig:performancetest},\ref{fig:performancetestlatency} and \ref{fig:performancetestamplitude}.  Table \ref{tab:results} shows the single-trial performance while identifying each letter of the standard P300 Speller Matrix, and the channel where the best performance was obtained.   Figure \ref{fig:performancetest} shows the performance curves for eight algorithms.  Each one represents the percentage of letters that were actually predicted by the combination of feature plus a classification method.  The data were divided in two, and the first 15 letters were used to derive the dictionary of templates $T$ while the remaining 20 letters were used to measure the classification accuracy.   Figure \ref{fig:performancetestlatency} shows the same results obtained when a Gaussian latency shift was added to each trial.   Finally, Figure \ref{fig:performancetestamplitude} represents the performance values obtained when the amplitude of the N1 and P3 component of the template are randomly reduced (uniform distribution).


\begin{table}[H]
\caption{Speller classification performance obtained for all the waveform-based algorithms: MP Matching Pursuit, HGO Histogram of Gradient Orientation, PE Permutation Entropy and SHCC Slope Horizontal Code Chain. Additionally, three control algorithms were included: RS Raw Signal, NN Neural Network and SVM Support Vector Machines.  All the methods process the signal on a channel-by-channel basis, hence the best performing channel is also shown. The mark \textit{m-c} is used on the control algorithms to identify that the feature was constructed using all the channels.  In this case with absence of null-signals, it can be interpreted as the channel that adds less noise to the ERP template. All the methods used $10$ intensification sequences to coherently average the trials to obtain the averaged signal. }
\centering
%% \tablesize{} %% You can specify the fontsize here, e.g.  \tablesize{\footnotesize}. If commented out \small will be used.
\begin{tabular}{ccc}
\toprule
\textbf{Method}	& \textbf{Channel} & \textbf{Single Trial Performance}	\\
\midrule
SVM     & m-c  & $50\%$ \\
NN       & m-c  & $45\%$ \\
HGO  & PO8 & $25\%$ \\
MP 1 & PO8 & $25\%$ \\
PE     & Cz & $20\%$ \\
RS     & Fz & $15\%$ \\
RS     & m-c  & $15\%$ \\
MP 2 & PO7 & $10\%$ \\
SHCC & P4 & $10\%$ \\
NN s-c & Fz & $10\%$ \\
\bottomrule
\end{tabular}
\label{tab:results}
\end{table}


\begin{figure}[H]
\centering
\includegraphics[width=15cm]{images/PerformanceTest.eps}
\caption{Speller performance obtained for each method.  Y-axis shows performance accuracy while X-axis shows the number of intensification sequences used to calculate the point-to-point signal average.}
\label{fig:performancetest}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=15cm]{images/PerformanceTestLatency.eps}
\caption{Speller performance obtained for each method while latencies were artificially added to each single-trial segment.  The achieved performance is significantly reduced for all methods.}
\label{fig:performancetestlatency}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=15cm]{images/PerformanceTestAmplitude.eps}
\caption{Speller performance obtained while the amplitudes of the N1 and P3 component of the superimposed ERP are randomly reduced.}
\label{fig:performancetestamplitude}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
\label{section:discussion}

The classification methods Support Vector Machine SVM and Artificial Neural Networks NN are added for comparison using the feature of Kasinksky (REF).  Additionally, the Kasinksky feature is used with the same classification algorithm as detailed in \ref{section:classification}.

All the methods show a significant reduction of performance when the latency noise is added, and at the same time all the methods show resistance to noise in peak amplitudes.

Except for the raw signal, using a multichannel feature provides a better synthesis of the differentiation information that provides a better accuracy.  This can be seen in Fig \ref{fig:performancetest} where the performance of the control algorithm NN is improved by using a multichannel feature.  The poor raw signal performance while using a multichannel feasture is likely to the curse of dimensionality due to the fact that the feature is simple too large.

Using a straightforward dictionary of templates for MP-1 proved more beneficial in terms of performance than the standard approach of using a Hilbert base of Wavelets atoms.

The methods \textit{HGO} and \textit{SHCC} performed much better than the other algorithms including when the latency and the amplitudes are noisy.

It is important to remark that Segmentation or identification is not considered in these experiments. The  problem of segmentation is related to the detection of a feature within an EEG trace and not to the feature extraction problem.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\label{section:conclusion}

The conventional clinical method of observing the waveform is understood to be subjective and laborious because results depend on the technicians' experience and expertise.  The need for more objective measurements pushed the adoption of more automated means of decoding the signals and demanded a need for replication \citep{Thakor2004}.  This lead to the initial development of quantitative EEG, which however didn't replaced clinically the traditional approach which is still widespread: the Gold standard in clinical EEG is still \textit{Eye Ball}

The purpose of this work was threefold, (1) raise awareness about the utility of using automatic waveform-based methods to study EEG signals, (2) to provide an overview of the state-of-the-art of those methods, and (3) to compare those methods and verify if it is possible to obtain classification accuracies based exclusively on the signal's waveform.

One of the main goals of the BCI discipline is to provide assistance to patients and to provide alternative tools to be used in diagnostics and rehabilitation procedure.  This requires a clinical focus which is often neglected in BCI research (ref).  At the same time, BCI reliability and the avoidance of the black box phenomena are goals that are still unfulfilled in this discipline(WOkpaw and wolpaw). The benefits of analysing or including metrics about the shape of the EEG, are that clinical EEG diagnosis may support a vast set of already understood knowledge which is based on identifying EEG patterns by their shape and that can lead to more robust implementation of BCI devices.

Successful approaches in Computer Vision or pattern recognition in other areas use a set of different features to compound ensemble classifiers.  All these methods had the advantage that they can truly map a visual component with a clinical meaning, assessed by a physician, and provide an automatic identification which can be constructed by the set of methods.  

More work has to be conducted in order to extend this methods to other patterns of waves.

The procedure of analysing signals by their waveforms is relative common in chemical analysis (i.e. chemometrics Skoog, D.; West, D.; Holler, F. Analtyical Chemistry, An Introduction; Saunders: Philadelphia, 1994.), geology (sismic analysis), and quantitive financial analysis.  EKG, or Electrocardiogram, on the other hand, has been extensively processed and analysed by waveform methods.
Additionally, the same problem can be found in Intelligent Character Recognition.

%Berger H: tiber das Elektrenkephalogramm des Menschen, Archiv Psychiatr, 87 (1929) pp. 527-570.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsection{Subsection}
%
%\subsubsection{Subsubsection}
%
%Bulleted lists look like this:
%\begin{itemize}[leftmargin=*,labelsep=4mm]
%\item	First bullet
%\item	Second bullet
%\item	Third bullet
%\end{itemize}
%
%Numbered lists can be added as follows:
%\begin{enumerate}[leftmargin=*,labelsep=3mm]
%\item	First item
%\item	Second item
%\item	Third item
%\end{enumerate}
%
%The text continues here.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{6pt} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\supplementary{The following are available online at www.mdpi.com/link, Figure S1: title, Table S1: title, Video S1: title.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\acknowledgments{This project was supported by the ITBACyT-15 funding program issued by ITBA University. We would like to thank to Dr. Valentina Unakafova for providing the Permutation Entropy algorithm and to Dr. Montserrat-Alvarado González for providing the source code and a detailed description of the SHCC algorithm.}

%We would like to thank to Dr. Jian Zhang for providing details of the MIDS algorithm, to Dr. Valentina Unakafova for providing the Permutation Entropy algorithm 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\authorcontributions{This projects is part of a the first author's PhD Thesis which is directed by Juan Miguel Santos and codirected by Ana Julia Villar.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\conflictofinterests{The authors declare no conflict of interest.} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
\abbreviations{The following abbreviations are used in this manuscript:\\

\noindent EEG: electroencephalography\\
BCI: Brain Computer Interfaces\\
SNR: Signal to Noise Ratio\\
CNS: Central Nervous System\\
ALS: Amyotrophic Lateral Sclerosis\\
ERP: Event-Related Potential\\
P300: Positive deflection of an Event-Related Potential which occurs 300 ms after onset of stimulus\\
ITR: Information Transfer Rate\\
BTR: Bit Transfer Rate\\
SIFT: Scale Invariant Feature Transform\\
HOG: Histogram Of Gradients}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\appendixtitles{no} %Leave argument "no" if all appendix headings stay EMPTY (then no dot is printed after "Appendix A"). If the appendix sections contain a heading then change the argument to "yes".
%\appendixsections{multiple} %Leave argument "multiple" if there are multiple sections. Then a counter is printed ("Appendix A?). If there is only one appendix section then change the argument to ?one? and no counter is printed (?Appendix?).
%\appendix
%\section{}
%The appendix is an optional section that can contain details and data supplemental to the main text. For example, explanations of experimental details that would disrupt the flow of the main text, but nonetheless remain crucial to understanding and reproducing the research shown; figures of replicates for experiments of which representative data is shown in the main text can be added here if brief, or as Supplementary data. Mathemtaical proofs of results not central to the paper can be added as an appendix.
%
%\section{}
%All appendix sections must be cited in the main text. In the appendixes, Figures, Tables, etc. should be labeled starting with `A', e.g., Figure A1, Figure A2, etc. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Citations and References in Supplementary files are permitted provided that they also appear in the reference list here. 
\bibliographystyle{mdpi}

%=====================================
% References, variant A: internal bibliography
%=====================================
%\renewcommand\bibname{References}
%\begin{thebibliography}{999}
% Reference 1
%\bibitem{ref-journal}
%Lastname, F.; Author, T. The title of the cited article. {\em Journal Abbreviation} {\bf 2008}, {\em 10}, 142-149.
% Reference 2
%\bibitem{ref-book}
%Lastname, F.F.; Author, T. The title of the cited contribution. In {\em The Book Title}; Editor, F., Meditor, A., Eds.; Publishing House: City, Country, 2007; pp. 32-58.
%\end{thebibliography}

%=====================================
% References, variant B: external bibliography
%=====================================
\bibliography{sensors}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional
%\sampleavailability{Samples of the compounds ...... are available from the authors.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}